# Week 4

- [Week 4](#week-4)
  - [Current Application](#current-application)
  - [To-Do](#to-do)
  - [Reference](#reference)


## Current Application

The current application only summarises online websites. 

I will try to add the following refinements as outlined in this [image](https://opea-project.github.io/latest/_images/docsum_architecture.png)

> The DocSum example is designed to process diverse content types—text documents, spoken language (audio), and visual media (video)—and generate concise summaries that capture the essence of the original material. This pipeline integrates ASR(automatic speech recognition) with an LLM using TGI to summarize the content. This example can be used to create summaries of news articles, research papers, technical documents, legal documents, multimedia documents, and other types of documents.

## To-Do

- Support for documents
- Support for freetext
- Support for OCR/Images
- Support for audio/video
- Support for YouTube videos as these are readily available
- Support for structured datasets

![Image](https://github.com/user-attachments/assets/6d725a0e-a032-4418-b846-89a03a25bfbc)

## Reference

- [https://opea-project.github.io/latest/tutorial/DocSum/DocSum_Guide.html](https://opea-project.github.io/latest/tutorial/DocSum/DocSum_Guide.html)