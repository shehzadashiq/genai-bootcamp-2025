# AWS Credentials - Required for AWS services (Polly, Transcribe, etc.)
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
AWS_DEFAULT_REGION=us-east-1
AWS_REGION=us-east-1
AWS_BUCKET_NAME=your-bucket-name

# Transcribe Service Configuration
TRANSSCRIBE_REGION=us-east-1

# Bedrock Configuration - Required for LLM services
BEDROCK_MODEL_ID=anthropic.claude-v2
BEDROCK_REGION=us-east-1

# Host Configuration
host_ip=localhost

# Proxy Configuration (if needed)
no_proxy=
http_proxy=
https_proxy=

# LLM Service Configuration
LLM_ENDPOINT_PORT=8008
LLM_MODEL_ID=llama3.2:1b

# Guardrails Service Configuration
GUARDRAILS_PORT=9090
HUGGING_FACE_TOKEN=your_huggingface_token
HUGGING_FACE_HUB_TOKEN=your_huggingface_token
HF_TOKEN=your_huggingface_token

# TGI Server Configuration
TGI_PORT=80
SAFETY_GUARD_MODEL_ID=meta-llama/Meta-Llama-Guard-2-8B
GUARDRAILS_COMPONENT_NAME=OPEA_LLAMA_GUARD
SAFETY_GUARD_ENDPOINT=http://${host_ip}:${TGI_PORT}
MAX_INPUT_TOKENS=2048
MAX_TOTAL_TOKENS=4096
DATA_PATH=./data

# Ollama Configuration
OLLAMA_PORT=11434

# API Configuration
PORT=8002
API_URL=http://localhost:8002

# Service Endpoints
DOCSUM_ENDPOINT=http://api:8002/summarize

# Cache Settings
CACHE_ENABLED=true

# Note: Replace all placeholder values (your_*) with actual values
# Make sure to keep this file secure and never commit it to version control
