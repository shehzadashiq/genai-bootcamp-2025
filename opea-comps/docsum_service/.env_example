# AWS Credentials
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1
AWS_REGION=us-east-1

# S3 Bucket Name which needs to be in your account
AWS_BUCKET_NAME=

# Transcribe Service Configuration
TRANSSCRIBE_REGION=us-east-1

# Google Application Credentials
GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/google_credentials.json

# Bedrock Configuration
BEDROCK_MODEL_ID=anthropic.claude-v2
BEDROCK_REGION=us-east-1

# Host Configuration
host_ip=localhost

# Proxy Configuration (if needed)
no_proxy=
http_proxy=
https_proxy=

# LLM Service Configuration
LLM_ENDPOINT_PORT=8008
LLM_MODEL_ID=llama3.2:1b

# Guardrails Service Configuration
GUARDRAILS_PORT=9090  # Updated port to match service
HUGGING_FACE_TOKEN=  # Replace with your actual token
HUGGING_FACE_HUB_TOKEN=
HF_TOKEN=

# TGI Server Configuration
TGI_PORT=80
SAFETY_GUARD_MODEL_ID="meta-llama/Meta-Llama-Guard-2-8B"
GUARDRAILS_COMPONENT_NAME=OPEA_LLAMA_GUARD
SAFETY_GUARD_ENDPOINT=http://${host_ip}:${TGI_PORT}
MAX_INPUT_TOKENS=2048
MAX_TOTAL_TOKENS=4096
DATA_PATH=./data

OLLAMA_PORT=11434

# API Configuration
PORT=8002
API_URL=http://localhost:8002

# Service Endpoints
DOCSUM_ENDPOINT=http://api:8002/summarize

# Cache Settings
CACHE_ENABLED=true
CACHE_TTL=3600